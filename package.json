{
  "name": "ai-coder-extension",
  "displayName": "AI Coder Extension",
  "description": "Расширение для разработки расширений генерации кода с использованием LLM",
  "version": "0.0.1",
  "engines": {
    "vscode": "^1.74.0"
  },
  "categories": [
    "Other"
  ],
  "activationEvents": [
    "onCommand:aiCoder.openPanel",
    "onCommand:aiCoder.markAsNotProcessed",
    "onCommand:aiCoder.markAsExcluded"
  ],
  "main": "./out/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "aiCoder.openPanel",
        "title": "Open AI Coder Panel"
      },
      {
        "command": "aiCoder.markAsNotProcessed",
        "title": "Сбросить статус",
        "icon": "$(circle-outline)"
      },
      {
        "command": "aiCoder.markAsExcluded",
        "title": "Исключить из обработки",
        "icon": "$(close)"
      },
      {
        "command": "aiCoder.clearAllStatuses",
        "title": "Очистить все статусы",
        "icon": "$(clear-all)"
      }
    ],
    "menus": {
      "commandPalette": [
        {
          "command": "aiCoder.openPanel"
        },
        {
          "command": "aiCoder.markAsNotProcessed"
        },
        {
          "command": "aiCoder.markAsExcluded"
        },
        {
          "command": "aiCoder.clearAllStatuses"
        }
      ],
      "view/title": [
        {
          "command": "aiCoder.openPanel",
          "when": "view == aiCoderPanel",
          "group": "navigation"
        }
      ],
      "explorer/context": [
        {
          "command": "aiCoder.markAsNotProcessed",
          "title": "AI Coder: Сбросить статус",
          "group": "aiCoder@1"
        },
        {
          "command": "aiCoder.markAsExcluded",
          "title": "AI Coder: Исключить из обработки",
          "group": "aiCoder@2"
        }
      ]
    },
    "configuration": {
      "title": "AI Coder",
      "properties": {
        "aiCoder.llm.provider": {
          "type": "string",
          "enum": [
            "openai",
            "anthropic",
            "ollama",
            "custom"
          ],
          "enumDescriptions": [
            "OpenAI (GPT-3.5, GPT-4)",
            "Anthropic Claude",
            "Ollama (локальные модели)",
            "Кастомный провайдер"
          ],
          "default": "openai",
          "description": "Провайдер LLM для генерации кода"
        },
        "aiCoder.llm.model": {
          "type": "string",
          "default": "gpt-4",
          "description": "Модель LLM (например: gpt-4, gpt-3.5-turbo, claude-3-opus)"
        },
        "aiCoder.llm.embedderModel": {
          "type": "string",
          "default": "",
          "description": "Модель эмбеддинга для создания векторных представлений текста (например: text-embedding-ada-002, nomic-embed-text)"
        },
        "aiCoder.llm.temperature": {
          "type": "number",
          "default": 0.7,
          "minimum": 0,
          "maximum": 2,
          "description": "Температура генерации (0-2). Более высокие значения делают вывод более креативным"
        },
        "aiCoder.llm.maxTokens": {
          "type": "number",
          "default": 2000,
          "minimum": 100,
          "maximum": 8000,
          "description": "Максимальное количество токенов в ответе"
        },
        "aiCoder.llm.baseUrl": {
          "type": "string",
          "default": "",
          "description": "Базовый URL для кастомного провайдера (опционально)"
        },
        "aiCoder.llm.apiType": {
          "type": "string",
          "enum": [
            "openai",
            "ollama"
          ],
          "enumDescriptions": [
            "OpenAI-совместимый API (LM Studio, vLLM и т.д.)",
            "Ollama-совместимый API"
          ],
          "default": "openai",
          "description": "Тип API для кастомного провайдера"
        },
        "aiCoder.llm.localUrl": {
          "type": "string",
          "default": "http://localhost:11434",
          "description": "URL локального сервера для Ollama или других локальных моделей"
        },
        "aiCoder.llm.timeout": {
          "type": "number",
          "default": 30000,
          "minimum": 5000,
          "maximum": 300000,
          "description": "Таймаут запроса в миллисекундах"
        },
        "aiCoder.llm.systemPrompt": {
          "type": "string",
          "default": "",
          "description": "Системный промпт для LLM. Определяет роль и поведение модели."
        },
        "aiCoder.llm.defaultModelOpenai": {
          "type": "string",
          "default": "gpt-4",
          "description": "Дефолтная модель для OpenAI провайдера"
        },
        "aiCoder.llm.defaultModelOllama": {
          "type": "string",
          "default": "llama2",
          "description": "Дефолтная модель для Ollama провайдера"
        },
        "aiCoder.llm.defaultModelLocalApi": {
          "type": "string",
          "default": "local-model",
          "description": "Дефолтная модель для локального API провайдера"
        },
        "aiCoder.llm.apiKeyNotNeeded": {
          "type": "string",
          "default": "not-needed",
          "description": "Значение API ключа, когда ключ не требуется"
        },
        "aiCoder.llm.availabilityCheckTimeoutLocalApi": {
          "type": "number",
          "default": 3000,
          "minimum": 1000,
          "maximum": 30000,
          "description": "Таймаут проверки доступности локального API (мс)"
        },
        "aiCoder.llm.availabilityCheckTimeoutOllama": {
          "type": "number",
          "default": 5000,
          "minimum": 1000,
          "maximum": 30000,
          "description": "Таймаут проверки доступности Ollama (мс)"
        },
        "aiCoder.llm.streamPollingDelay": {
          "type": "number",
          "default": 10,
          "minimum": 1,
          "maximum": 1000,
          "description": "Задержка между проверками потока данных (мс)"
        },
        "aiCoder.llm.promptFormatOllamaSystemPrefix": {
          "type": "string",
          "default": "\n\nUser request: ",
          "description": "Префикс для системного промпта Ollama"
        },
        "aiCoder.llm.promptFormatOllamaCodeSuffix": {
          "type": "string",
          "default": "\n\nCode:",
          "description": "Суффикс для промпта генерации кода Ollama"
        },
        "aiCoder.llm.sseDataPrefix": {
          "type": "string",
          "default": "data: ",
          "description": "Префикс для данных в SSE потоке"
        },
        "aiCoder.llm.sseDoneMarker": {
          "type": "string",
          "default": "[DONE]",
          "description": "Маркер завершения SSE потока"
        },
        "aiCoder.vectorization.summarizePrompt": {
          "type": "string",
          "default": "Суммаризируй следующий код или текст. Создай краткое описание основных функций, классов, методов и их назначения. Сохрани важные детали, но сделай текст более компактным и структурированным.",
          "description": "Промпт для суммаризации файлов при векторизации. Используется для создания краткого описания содержимого файлов."
        },
        "aiCoder.vectorization.enableOrigin": {
          "type": "boolean",
          "default": true,
          "description": "Создавать векторы по оригинальному тексту файлов"
        },
        "aiCoder.vectorization.enableSummarize": {
          "type": "boolean",
          "default": false,
          "description": "Создавать векторы по суммаризации файлов"
        },
        "aiCoder.vectorization.enableVsOrigin": {
          "type": "boolean",
          "default": true,
          "description": "Создавать векторы как сумму векторов по оригинальному тексту вложений"
        },
        "aiCoder.vectorization.enableVsSummarize": {
          "type": "boolean",
          "default": true,
          "description": "Создавать векторы как сумму векторов по суммаризации вложений"
        },
        "aiCoder.vectorization.maxTextLength": {
          "type": "number",
          "default": 10000,
          "minimum": 1000,
          "maximum": 100000,
          "description": "Максимальная длина текста для суммаризации (~2500-3000 токенов)"
        },
        "aiCoder.vectorization.truncateMessage": {
          "type": "string",
          "default": "\n\n[...текст обрезан для суммаризации...]",
          "description": "Сообщение, добавляемое при обрезке текста для суммаризации"
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "npm run compile",
    "compile": "tsc -p ./",
    "watch": "tsc -watch -p ./"
  },
  "devDependencies": {
    "@types/node": "16.x",
    "@types/node-fetch": "^2.6.13",
    "@types/vscode": "^1.74.0",
    "typescript": "^4.9.4"
  },
  "dependencies": {
    "@lancedb/lancedb": "^0.5.2",
    "node-fetch": "^2.7.0"
  }
}
